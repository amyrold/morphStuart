---
title: "morphStuart"
author: "Aaron Myrold"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```
#==============================================================================#
# PROJECT INTRODUCTION

#==============================================================================#
# SETUP
## Loading Libraries
```{r Libraries, include=FALSE}
# load libraries needed for our analyses
# 1 ggplot2
if (!require("ggplot2")) install.packages("ggplot2")
library(ggplot2)

# 2 dplyr
if (!require("dplyr")) install.packages("dplyr")
library(dplyr)

# 3 tidyr
if (!require("tidyr")) install.packages("tidyr")
library(tidyr)

# 4 stringr
if (!require("stringr")) install.packages("stringr")
library(stringr)

```

## Global Variables
```{r Global Variables, include=FALSE}
# store current user's working directory
wk.dir <- getwd()
# Set seed for reproducibility
set.seed(333)

```

## Folder Management
```{r Folder Management, include=FALSE}

# This is a function to initialize a new project
  # It creates required subfolders (see defaults) 
  # It outputs an object that stores the relative paths to these sub-folders

# If calling the function within the working directory of the project, project_number = 0
  # this will create necessary sub-folders in current working directory

# If creating a new root folder for the project, provide project_number >=1 and a project_name
  # this will create a folder "pX.project_name/" to store all sub-folders
new_project <- function(project_number, project_name = NULL, subfolders = NULL, wk.dir = getwd()) {
  # Set default subfolders
  default_subfolders <- c("data", "scripts", "output", "docs")
  
  # Use provided sub-folders or defaults if none are provided
  if (is.null(subfolders)) {
    subfolders <- default_subfolders
  }
  
  # Initialize project paths list
  project_paths <- list()
  
  # Check if this is a "root directory" project (project_number = 0)
  is_root_project <- project_number == 0
  
  if (is_root_project) {
    # Use working directory as the base path for root projects
    base_path <- wk.dir
    project_paths$main <- wk.dir
    message("Creating folders directly in working directory: ", wk.dir)
  } else {
    # For normal projects, validate project name is provided
    if (is.null(project_name)) {
      stop("Project name is required when project_number is not 0")
    }
    
    # Create project folder name
    project_folder <- paste0("p", project_number, ".", project_name)
    
    # Full path for the project folder
    project_path <- file.path(wk.dir, project_folder)
    
    # Create the project folder if it doesn't exist
    if (!file.exists(project_path)) {
      dir.create(project_path)
      message("Created project folder: ", project_path)
    } else {
      message("Project folder already exists: ", project_path)
    }
    
    # Set base path for subfolders
    base_path <- project_path
    project_paths$main <- project_path
  }
  
  # Create sub-folders
  for (sub in subfolders) {
    # Determine subfolder name based on project type
    if (is_root_project) {
      subfolder_name <- sub
    } else {
      subfolder_name <- paste0("p", project_number, ".", sub)
    }
    
    # Full path for the subfolder
    subfolder_path <- file.path(base_path, subfolder_name)
    
    # Create sub-folder if it doesn't exist
    if (!file.exists(subfolder_path)) {
      dir.create(subfolder_path, recursive = TRUE)  # Added recursive=TRUE for nested paths
      message("Created subfolder: ", subfolder_path)
    } else {
      message("Subfolder already exists: ", subfolder_path)
    }
    
    # Add the sub-folder path to the list
    project_paths[[sub]] <- paste0(subfolder_path, "/")
  }
  
  # Return the list of paths as an object
  return(project_paths)
}

```

## Initialize Directories
```{r}
# Initialize new project directories
p <- new_project(0, subfolders = c("1.data", "1.data/a.raw", "1.data/b.merged",
                                   "1.data/c.flagged","1.data/d.processed", 
                                   "2.scripts", "3.outputs", "4.docs"))
```

#==============================================================================#
# FUNCTIONS
## variable_mapping
```{r}
variable_mapping <- function() {
  # Define measurement types
  continuous_vars <- c("SL", "CAV", "DS1", "DS2", "DS3", "LPT", 
                      "PSP.L", "PSP.R", "TPG", "ECT", "CLE", "PMX")
  
  count_vars <- c("MDF", "MAF", "MCV", "MAV", "MPT", "MPSP")
  
  binary_vars <- c("MDS1", "MDS2", "MDS3", "MDS1NA", 
                   "MDS2NA", "MDS3NA", "MPSPNA")
  
  # Return as a list
  return(list(
    continuous = continuous_vars,
    count = count_vars,
    binary = binary_vars,
    all = c(continuous_vars, count_vars, binary_vars)
  ))
}
```

## handle_special_cases
```{r}
handle_special_cases <- function(data) {
  # requires dplyr
  
  # Use dplyr to handle all the special cases with cleaner syntax
  cleaned <- data %>%
    as_tibble() %>%
    # Handle dorsal spine columns - use case_when for readable conditional logic
    mutate(
      # Dorsal spine 1
      DS1 = case_when(
        MDS1 == 0 & MDS1NA == 1 ~ NA_real_,
        MDS1 == 0 & MDS1NA == 0 & is.na(DS1) ~ 0,
        TRUE ~ DS1
      ),
      # Dorsal spine 2
      DS2 = case_when(
        MDS2 == 0 & MDS2NA == 1 ~ NA_real_,
        MDS2 == 0 & MDS2NA == 0 & is.na(DS2) ~ 0,
        TRUE ~ DS2
      ),
      # Dorsal spine 3
      DS3 = case_when(
        MDS3 == 0 & MDS3NA == 1 ~ NA_real_,
        MDS3 == 0 & MDS3NA == 0 & is.na(DS3) ~ 0,
        TRUE ~ DS3
      ),
      
      # Handle MPT (pre-dorsal pterygiophores)
      MPT = case_when(
        MPT == 0 & (MDS1 == 1 | MDS2 == 1 | MDS3 == 1) ~ NA_real_,
        TRUE ~ MPT
      ),
      
      # Handle pelvic spine columns
      PSP.L = case_when(
        MPSP == 0 & MPSPNA == 1 ~ NA_real_,
        TRUE ~ PSP.L
      ),
      PSP.R = case_when(
        MPSP == 0 & MPSPNA == 1 ~ NA_real_,
        TRUE ~ PSP.R
      )
    )
  
  # When TPGNA column is available, apply similar logic to TPG
  if ("TPGNA" %in% names(cleaned)) {
    cleaned <- cleaned %>%
      mutate(
        TPG = case_when(
          TPGNA == 1 ~ NA_real_,
          TRUE ~ TPG
        )
      )
  }
  
  return(as.data.frame(cleaned))
}

```

## identify_overlaps
```{r}
identify_overlaps <- function(data, threshold = 0.05) {
  # Requires tidyr and dplyr
  
  # Get variable mappings
  var_map <- variable_mapping()
  
  # Step 1: Create separate dataframes for part and counterpart data
  part_data <- data %>% 
    filter(part_type == "P") %>%
    select(fish_id, part_type, row_id = n, Scale_10mm, all_of(var_map$all))
  
  cpart_data <- data %>% 
    filter(part_type == "C") %>%
    select(fish_id, part_type, row_id = n, Scale_10mm, all_of(var_map$all))
  
  # Step 2: For each fish and measurement, aggregate values to avoid many-to-many joins
  # This preserves information about which fish have duplicates without creating cartesian products
  part_agg <- part_data %>%
    pivot_longer(
      cols = all_of(var_map$all),
      names_to = "measure",
      values_to = "value"
    ) %>%
    filter(!is.na(value)) %>%
    group_by(fish_id, measure) %>%
    summarize(
      part_value = if(first(measure) %in% var_map$binary) max(value) else mean(value),
      part_scale = mean(Scale_10mm, na.rm = TRUE),
      has_multiple_values = n() > 1,
      .groups = "drop"
    )
  
  cpart_agg <- cpart_data %>%
    pivot_longer(
      cols = all_of(var_map$all),
      names_to = "measure",
      values_to = "value"
    ) %>%
    filter(!is.na(value)) %>%
    group_by(fish_id, measure) %>%
    summarize(
      cpart_value = if(first(measure) %in% var_map$binary) max(value) else mean(value),
      cpart_scale = mean(Scale_10mm, na.rm = TRUE),
      has_multiple_values = n() > 1,
      .groups = "drop"
    )
  
  # Step 3: Join part and counterpart data to find overlaps (now a one-to-one join)
  overlaps <- part_agg %>%
    inner_join(cpart_agg, by = c("fish_id", "measure"))
  
  # Step 4: Calculate differences with appropriate handling for each variable type
  overlaps <- overlaps %>%
    mutate(
      var_type = case_when(
        measure %in% var_map$continuous ~ "continuous",
        measure %in% var_map$count ~ "count",
        measure %in% var_map$binary ~ "binary",
        TRUE ~ "other"
      ),
      scale = coalesce((part_scale + cpart_scale) / 2, part_scale, cpart_scale),
      absolute_diff = abs(part_value - cpart_value),
      
      # Modified approach for different variable types
      relative_diff = case_when(
        # For continuous: relative to scale
        var_type == "continuous" & scale > 0 ~ absolute_diff / scale,
        # For count: proportion of max value
        var_type == "count" ~ absolute_diff / max(1, pmax(part_value, cpart_value)),
        # For binary: 0 or 1
        TRUE ~ as.numeric(absolute_diff > 0)
      ),
      
      # Flag criteria - customized by variable type
      exceeds_threshold = case_when(
        var_type == "continuous" ~ relative_diff > threshold,
        var_type == "count" ~ absolute_diff > 0, # Any difference in counts
        var_type == "binary" ~ FALSE, # Never flag binary (we'll take max)
        TRUE ~ FALSE
      ),
      
      # Additional flag if either part/counterpart has multiple values for this measure
      multiple_measurements = has_multiple_values.x | has_multiple_values.y
    )
  
  # Step 5: Determine fish to flag based on any exceeding threshold
  fish_to_flag <- overlaps %>%
    filter(exceeds_threshold) %>%
    select(fish_id) %>%
    distinct() %>%
    pull(fish_id)
  
  # Step 6: Split data into flagged and non-flagged groups
  # This maintains the original structure (multiple rows possible per fish/part)
  overlap_fish <- data %>%
    filter(fish_id %in% fish_to_flag)
  
  non_overlap_fish <- data %>%
    filter(!fish_id %in% fish_to_flag)
  
  # Return original format data frames
  return(list(
    overlap_fish = as.data.frame(overlap_fish),
    non_overlap_fish = as.data.frame(non_overlap_fish),
    overlap_metrics = as.data.frame(overlaps)
  ))
}

```
## merge_non_overlap
```{r}
merge_non_overlap <- function(data) {
  # requires dplyr and tidyr
  
  # Get variable mappings for specialized handling
  var_map <- variable_mapping()
  
  # Get unique fish IDs
  fish_ids <- unique(data$fish_id)
  
  # Define metadata columns (non-measurement columns)
  id_cols <- c("n", "ID", "fish_id", "part_type", "bin")
  measure_cols <- setdiff(names(data), id_cols)
  
  # Initialize empty dataframe for results
  result_list <- list()
  
  # Process each fish
  for (i in seq_along(fish_ids)) {
    id <- fish_ids[i]
    
    # Get all data for this fish
    fish_data <- data %>% 
      filter(fish_id == id)
    
    # Get part and counterpart data
    part_data <- fish_data %>% filter(part_type == "P")
    cpart_data <- fish_data %>% filter(part_type == "C")
    
    # Create a results row
    result_row <- data.frame(fish_id = id)
    
    # If only one part type exists, use that directly (but still aggregate if multiple rows)
    if (nrow(part_data) == 0) {
      # No part data, use aggregated counterpart data
      if (nrow(cpart_data) > 0) {
        # Use first row for metadata
        template_row <- cpart_data[1,]
        for (col in id_cols) {
          if (col != "part_type") {
            result_row[[col]] <- template_row[[col]]
          } else {
            result_row[[col]] <- "merged"
          }
        }
        
        # Aggregate counterpart measurements
        for (col in measure_cols) {
          var_type <- "continuous"  # default
          if (col %in% var_map$binary) var_type <- "binary"
          if (col %in% var_map$count) var_type <- "count"
          
          values <- cpart_data[[col]]
          values <- values[!is.na(values)]
          
          if (length(values) > 0) {
            if (var_type %in% c("binary", "count")) {
              result_row[[col]] <- max(values)
            } else {
              result_row[[col]] <- mean(values)
            }
          } else {
            result_row[[col]] <- NA
          }
        }
      }
      result_row$part_type <- "merged"
      result_row$merged <- TRUE
      result_list[[i]] <- result_row
      next
    } else if (nrow(cpart_data) == 0) {
      # No counterpart data, use aggregated part data
      # Use first row for metadata
      template_row <- part_data[1,]
      for (col in id_cols) {
        if (col != "part_type") {
          result_row[[col]] <- template_row[[col]]
        } else {
          result_row[[col]] <- "merged"
        }
      }
      
      # Aggregate part measurements
      for (col in measure_cols) {
        var_type <- "continuous"  # default
        if (col %in% var_map$binary) var_type <- "binary"
        if (col %in% var_map$count) var_type <- "count"
        
        values <- part_data[[col]]
        values <- values[!is.na(values)]
        
        if (length(values) > 0) {
          if (var_type %in% c("binary", "count")) {
            result_row[[col]] <- max(values)
          } else {
            result_row[[col]] <- mean(values)
          }
        } else {
          result_row[[col]] <- NA
        }
      }
      result_row$part_type <- "merged"
      result_row$merged <- TRUE
      result_list[[i]] <- result_row
      next
    }
    
    # Both part and counterpart exist - aggregate them separately then merge
    
    # Use first part row for metadata
    template_row <- part_data[1,]
    for (col in id_cols) {
      if (col != "part_type") {
        result_row[[col]] <- template_row[[col]]
      } else {
        result_row[[col]] <- "merged"
      }
    }
    result_row$merged <- TRUE
    
    # For each measurement column, aggregate first, then merge values prioritizing part over counterpart
    for (col in measure_cols) {
      # Determine variable type
      var_type <- "continuous"  # default
      if (col %in% var_map$binary) var_type <- "binary"
      if (col %in% var_map$count) var_type <- "count"
      
      # Aggregate part values
      part_vals <- part_data[[col]]
      part_vals <- part_vals[!is.na(part_vals)]
      part_val <- NA
      if (length(part_vals) > 0) {
        if (var_type %in% c("binary", "count")) {
          part_val <- max(part_vals)
        } else {
          part_val <- mean(part_vals)
        }
      }
      
      # Aggregate counterpart values
      cpart_vals <- cpart_data[[col]]
      cpart_vals <- cpart_vals[!is.na(cpart_vals)]
      cpart_val <- NA
      if (length(cpart_vals) > 0) {
        if (var_type %in% c("binary", "count")) {
          cpart_val <- max(cpart_vals)
        } else {
          cpart_val <- mean(cpart_vals)
        }
      }
      
      # Priority: part > counterpart
      if (!is.na(part_val)) {
        result_row[[col]] <- part_val
      } else if (!is.na(cpart_val)) {
        result_row[[col]] <- cpart_val
      } else {
        result_row[[col]] <- NA
      }
    }
    
    # Add to result list
    result_list[[i]] <- result_row
  }
  
  # Combine all results
  result <- bind_rows(result_list)
  
  # Ensure all original columns exist in output
  for (col in names(data)) {
    if (!(col %in% names(result))) {
      result[[col]] <- NA
    }
  }
  
  # Add merged flag if not already present
  if (!("merged" %in% names(result))) {
    result$merged <- TRUE
  }
  
  return(as.data.frame(result))
}
```

## create_review_list
```{r}
create_review_list <- function(overlap_results, use_threshold = TRUE) {
  # requires dplyr
  metrics <- overlap_results$overlap_metrics
  
  # Get variable mappings
  var_map <- variable_mapping()
  
  # First, optionally filter the metrics based on use_threshold parameter
  filtered_metrics <- if(use_threshold) {
    metrics %>% filter(exceeds_threshold == TRUE)
  } else {
    metrics
  }
  
  # Add more meaningful grouping and sorting
  summary <- filtered_metrics %>%
    # First summarize by fish and variable type
    group_by(fish_id, var_type) %>%
    summarize(
      num_overlapping = n(),
      # For continuous vars, calculate max difference
      max_relative_diff = if_else(
        first(var_type) == "continuous", 
        max(relative_diff, na.rm = TRUE), 
        NA_real_
      ),
      .groups = "drop"
    ) %>%
    # Then create a summary by fish
    group_by(fish_id) %>%
    summarize(
      continuous_diffs = sum(var_type == "continuous"),
      count_diffs = sum(var_type == "count"),
      binary_diffs = sum(var_type == "binary"),  # Should be 0 if use_threshold is TRUE
      total_diffs = n(),
      max_relative_diff = max(max_relative_diff, na.rm = TRUE),
      .groups = "drop"
    ) %>%
    # Sort by total differences
    arrange(desc(total_diffs), desc(continuous_diffs))
  
  # Create a more detailed breakdown by measurement type
  details <- filtered_metrics %>%
    arrange(fish_id, var_type, desc(relative_diff))
  
  return(list(
    summary = as.data.frame(summary),
    details = as.data.frame(details),
    filtered_metrics = as.data.frame(filtered_metrics),
    use_threshold = use_threshold
  ))
}
```

## export_review_list
```{r}
export_review_list <- function(review_results, file_prefix = "fish_review", 
                               output_dir = NULL) {
  # Create output directory if specified and it doesn't exist
  if (!is.null(output_dir)) {
    if (!dir.exists(output_dir)) {
      dir.create(output_dir, recursive = TRUE)
    }
    summary_path <- file.path(output_dir, paste0(file_prefix, "_summary.csv"))
    details_path <- file.path(output_dir, paste0(file_prefix, "_details.csv"))
  } else {
    summary_path <- paste0(file_prefix, "_summary.csv")
    details_path <- paste0(file_prefix, "_details.csv")
  }
  
  # Export files
  readr::write_csv(review_results$summary, summary_path)
  readr::write_csv(review_results$details, details_path)
  
  # Return file paths
  return(list(
    summary = summary_path,
    details = details_path
  ))
}

```

## validate_data
```{r}
# Add a validation function to ensure data quality
validate_data <- function(original, corrected, merged, overlaps) {
  # requires dplyr
  
  # Initialize results
  validation <- list()
  
  # Check if any rows were lost
  total_specimens_original <- length(unique(original$fish_id))
  total_specimens_after <- length(unique(c(
    merged$fish_id, 
    unique(overlaps$fish_id)
  )))
  
  validation$all_specimens_accounted_for <- 
    total_specimens_original == total_specimens_after
  
  validation$specimen_counts <- tibble(
    stage = c("Original", "Merged", "Flagged for review", "Total after processing"),
    count = c(
      total_specimens_original,
      length(unique(merged$fish_id)),
      length(unique(overlaps$fish_id)),
      total_specimens_after
    )
  )
  
  # Check special case handling
  special_case_check <- corrected %>%
    filter(
      (MDS1 == 0 & MDS1NA == 1 & !is.na(DS1)) |
      (MDS2 == 0 & MDS2NA == 1 & !is.na(DS2)) |
      (MDS3 == 0 & MDS3NA == 1 & !is.na(DS3)) |
      (MPT == 0 & (MDS1 == 1 | MDS2 == 1 | MDS3 == 1)) |
      (MPSP == 0 & MPSPNA == 1 & (!is.na(PSP.L) | !is.na(PSP.R)))
    )
  
  validation$special_cases_properly_handled <- nrow(special_case_check) == 0
  validation$problematic_rows <- special_case_check
  
  return(validation)
}

```

```{r}


```

```{r}


```

#==============================================================================#
# DATA IMPORT
```{r}
# Read in data and check initial structure
morph <- read.csv(paste0(p$`1.data/a.raw`, "241015_PitLMorph.csv"))
# str(morph)
```

## ID Structure Analysis
```{r}
# Extract fish ID and part type
# ID format: VXXXXXX_LXXXX(A)_1_P/C.jpg 
# where VXXXXXX is the specimen ID, LXXXX(A) is the bin/locality, and P/C indicates part/counterpart
morph <- morph %>%
  mutate(
    fish_id = str_extract(ID, "^V\\d+"),                          # Extract VXXXXX part at beginning
    bin_raw = str_extract(ID, "L\\d+[A-Za-z]?"),                  # Extract LXXXX with optional letter
    # Split bin into letter prefix, number, and suffix
    bin_letter = str_extract(bin_raw, "^L"),
    bin_number = str_extract(bin_raw, "\\d+"),
    bin_suffix = str_extract(bin_raw, "[A-Za-z]$"),
    # Create standardized bin with zero padding
    bin = case_when(
      !is.na(bin_suffix) ~ paste0(bin_letter, str_pad(bin_number, 4, pad = "0"), bin_suffix),
      !is.na(bin_number) ~ paste0(bin_letter, str_pad(bin_number, 4, pad = "0")),
      TRUE ~ NA_character_
    ),
    part_type = str_extract(ID, "[PC](?=\\.jpg$)")               # Extract P or C before .jpg
  ) %>%
  select(-bin_raw, -bin_letter, -bin_number, -bin_suffix)        # Remove intermediate columns

# Count rows per fish and part type
fish_part_counts <- morph %>%
  group_by(fish_id, part_type) %>%
  summarise(row_count = n(), .groups = "drop") %>%
  pivot_wider(names_from = part_type, values_from = row_count, values_fill = 0)

# Check fish without both part types
missing_parts <- fish_part_counts %>%
  filter(P == 0 | C == 0)
sum(missing_parts$`NA`) # 14 fish without both "part" & "counter part"

# Fish with excessive rows
multi_row_fish <- fish_part_counts %>%
  filter(P > 1 | C > 1)
length(multi_row_fish$fish_id) # 374 fish with duplicate "parts" or "counter parts"

```

## Basic Quality Check
```{r}
# Check for implausible values in measurement columns
length_cols <- c("SL", "CAV", "DS1", "DS2", "DS3", "LPT", "PSP.L", "PSP.R", "TPG", "ECT", "CLE", "PMX")

# Check for negative values in length columns
negative_lengths <- morph %>%
  select(ID, all_of(length_cols)) %>%
  pivot_longer(cols = -ID, names_to = "measure", values_to = "value") %>%
  filter(value < 0)
length(negative_lengths$ID) # No negative measurements

```

## Flag missing Scale_10mm
```{r}
# Check for missing scale information
scale_summary <- morph %>%
  group_by(fish_id) %>%
  summarize(
    has_part_scale = any(!is.na(Scale_10mm[part_type == "P"])),
    has_cpart_scale = any(!is.na(Scale_10mm[part_type == "C"])),
    has_any_scale = has_part_scale | has_cpart_scale,
    .groups = "drop"
  )

# Get list of fish IDs missing scales
fish_missing_scales <- scale_summary %>%
  filter(!has_any_scale) %>%
  pull(fish_id)

# Create report of fish missing scale information
missing_scales_detail <- morph %>%
  filter(fish_id %in% fish_missing_scales) %>%
  select(fish_id, ID, part_type, Scale_10mm) %>%
  arrange(fish_id, part_type)

# Write the detailed report
write.csv(missing_scales_detail, 
          file = paste0(p$`1.data/c.flagged`, "/fish_missing_scales_detailed.csv"), 
          row.names = FALSE)

# Print summary of scale check
cat("Fish without any scale information:", 
    sum(!scale_summary$has_any_scale), 
    "out of", nrow(scale_summary), "\n")

# Split the dataset
morph_with_scales <- morph %>%
  filter(!fish_id %in% fish_missing_scales)

morph_without_scales <- morph %>%
  filter(fish_id %in% fish_missing_scales)

# Continue with the fish that have scale measurements
morph <- morph_with_scales

# Write the datasets to separate files for reference
write.csv(morph_with_scales, 
          file = paste0(p$`1.data/a.raw`, "/fish_with_scales.csv"), 
          row.names = FALSE)

write.csv(morph_without_scales, 
          file = paste0(p$`1.data/c.flagged`, "/fish_without_scales.csv"), 
          row.names = FALSE)
```

#==============================================================================#
# DATA PREPROCESSING
## Handle Special Cases
```{r Spine and Girdle Logic}

morph_corrected <- handle_special_cases(morph)

```

## Overlap Assesment
```{r}
overlap_results <- identify_overlaps(morph_corrected, threshold = 0.05)

# Summarize overlap findings
cat("Number of fish with overlapping measurements:", 
    length(unique(overlap_results$overlap_metrics$fish_id)), "\n")
cat("Number of fish without overlaps:", 
    length(unique(overlap_results$non_overlap_fish$fish_id)), "\n")

```

#==============================================================================#
# DATA CLEANING
## Merge Non-Overlapping Fish
```{r}
merged_non_overlap <- merge_non_overlap(overlap_results$non_overlap_fish)

# Write merged data for Non-Overlapping Fish
write.csv(merged_non_overlap, 
          file = paste0(p$`1.data/b.merged`, "/merged_non_overlap.csv"))
```

## Flag Conflicting Measurements
```{r Flag Duplicates}
# Create review list with threshold filtering applied (default)
review_results <- create_review_list(overlap_results, use_threshold = TRUE)

# Or to see all overlaps without threshold filtering:
# review_results_all <- create_review_list(overlap_results, use_threshold = FALSE)

export_review_list(review_results, file_prefix = "fish_fossil_review",
                   output_dir = p$`1.data/c.flagged`)

```

## Visualize Results
```{r}
# Get the filtered metrics that only include real overlaps
filtered_metrics <- review_results$filtered_metrics

# Create a suffix for titles based on whether threshold filtering was used
threshold_text <- if(review_results$use_threshold) " (Exceeding Threshold)" else " (All Overlaps)"

# Visualization 1: Distribution of relative differences
ggplot(filtered_metrics, aes(x = relative_diff)) +
  geom_histogram(bins = 30, fill = "skyblue", color = "black") +
  geom_vline(xintercept = 0.05, color = "red", linetype = "dashed") +
  labs(title = paste0("Distribution of Relative Differences", threshold_text),
       x = "Relative Difference (proportion of scale)",
       y = "Count") +
  theme_minimal()

# Visualization 2: Count of overlaps by measurement type
overlap_by_measure <- filtered_metrics %>%
  group_by(measure) %>%
  summarise(
    count = n(),
    avg_diff = mean(relative_diff, na.rm = TRUE),
    .groups = "drop"
  )

ggplot(overlap_by_measure, aes(x = reorder(measure, count), y = count)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = paste0("Number of fish with duplicate measurements by type", threshold_text),
       x = "Measurement",
       y = "Count of fish with duplicates") 

# Visualization 3: Distribution of flags per fish
ggplot(review_results$summary, aes(x = total_diffs)) +
  geom_histogram(binwidth = 1, fill = "coral") +
  theme_minimal() +
  labs(title = paste0("Distribution of duplicate measurements per fish", threshold_text),
       x = "Number of duplicate measurements",
       y = "Count of fish")

# Visualization 4: Distribution of differences by variable type
ggplot(filtered_metrics, 
       aes(x = var_type, y = absolute_diff, fill = var_type)) +
  geom_boxplot() +
  scale_fill_brewer(palette = "Set2") +
  theme_minimal() +
  labs(title = paste0("Distribution of Differences by Variable Type", threshold_text),
       x = "Variable Type", 
       y = "Absolute Difference",
       fill = "Variable Type") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

#==============================================================================#
