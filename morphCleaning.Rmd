---
title: "morphStuart"
author: "Aaron Myrold"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```
#==============================================================================#
# PROJECT INTRODUCTION

#==============================================================================#
# SETUP
## Loading Libraries
```{r Libraries, include=FALSE}
# load libraries needed for our analyses
# 1 ggplot2
if (!require("ggplot2")) install.packages("ggplot2")
library(ggplot2)

# 2 dplyr
if (!require("dplyr")) install.packages("dplyr")
library(dplyr)

# 3 tidyr
if (!require("tidyr")) install.packages("tidyr")
library(tidyr)

# 4 stringr
if (!require("stringr")) install.packages("stringr")
library(stringr)

```

## Global Variables
```{r Global Variables, include=FALSE}
# store current user's working directory
wk.dir <- getwd()
# Set seed for reproducibility
set.seed(333)

```

## Folder Management
```{r Folder Management, include=FALSE}

# This is a function to initialize a new project
  # It creates required subfolders (see defaults) 
  # It outputs an object that stores the relative paths to these sub-folders

# If calling the function within the working directory of the project, project_number = 0
  # this will create necessary sub-folders in current working directory

# If creating a new root folder for the project, provide project_number >=1 and a project_name
  # this will create a folder "pX.project_name/" to store all sub-folders
new_project <- function(project_number, project_name = NULL, subfolders = NULL, wk.dir = getwd()) {
  # Set default subfolders
  default_subfolders <- c("data", "scripts", "output", "docs")
  
  # Use provided sub-folders or defaults if none are provided
  if (is.null(subfolders)) {
    subfolders <- default_subfolders
  }
  
  # Initialize project paths list
  project_paths <- list()
  
  # Check if this is a "root directory" project (project_number = 0)
  is_root_project <- project_number == 0
  
  if (is_root_project) {
    # Use working directory as the base path for root projects
    base_path <- wk.dir
    project_paths$main <- wk.dir
    message("Creating folders directly in working directory: ", wk.dir)
  } else {
    # For normal projects, validate project name is provided
    if (is.null(project_name)) {
      stop("Project name is required when project_number is not 0")
    }
    
    # Create project folder name
    project_folder <- paste0("p", project_number, ".", project_name)
    
    # Full path for the project folder
    project_path <- file.path(wk.dir, project_folder)
    
    # Create the project folder if it doesn't exist
    if (!file.exists(project_path)) {
      dir.create(project_path)
      message("Created project folder: ", project_path)
    } else {
      message("Project folder already exists: ", project_path)
    }
    
    # Set base path for subfolders
    base_path <- project_path
    project_paths$main <- project_path
  }
  
  # Create sub-folders
  for (sub in subfolders) {
    # Determine subfolder name based on project type
    if (is_root_project) {
      subfolder_name <- sub
    } else {
      subfolder_name <- paste0("p", project_number, ".", sub)
    }
    
    # Full path for the subfolder
    subfolder_path <- file.path(base_path, subfolder_name)
    
    # Create sub-folder if it doesn't exist
    if (!file.exists(subfolder_path)) {
      dir.create(subfolder_path, recursive = TRUE)  # Added recursive=TRUE for nested paths
      message("Created subfolder: ", subfolder_path)
    } else {
      message("Subfolder already exists: ", subfolder_path)
    }
    
    # Add the sub-folder path to the list
    project_paths[[sub]] <- paste0(subfolder_path, "/")
  }
  
  # Return the list of paths as an object
  return(project_paths)
}

```

## Initialize Directories
```{r}
# Initialize new project directories
p <- new_project(0, subfolders = c("1.data", "1.data/a.raw", "1.data/b.merged",
                                   "1.data/c.flagged","1.data/d.processed", 
                                   "2.scripts", "3.outputs", "4.docs"))
```

#==============================================================================#
# FUNCTIONS
## handle_special_cases
```{r}
handle_special_cases <- function(data) {
  # Load necessary packages
  if (!requireNamespace("dplyr", quietly = TRUE)) {
    install.packages("dplyr")
  }
  library(dplyr)
  
  # Use dplyr to handle all the special cases with cleaner syntax
  cleaned <- data %>%
    as_tibble() %>%
    # Handle dorsal spine columns - use case_when for readable conditional logic
    mutate(
      # Dorsal spine 1
      DS1 = case_when(
        MDS1 == 0 & MDS1NA == 1 ~ NA_real_,
        MDS1 == 0 & MDS1NA == 0 & is.na(DS1) ~ 0,
        TRUE ~ DS1
      ),
      # Dorsal spine 2
      DS2 = case_when(
        MDS2 == 0 & MDS2NA == 1 ~ NA_real_,
        MDS2 == 0 & MDS2NA == 0 & is.na(DS2) ~ 0,
        TRUE ~ DS2
      ),
      # Dorsal spine 3
      DS3 = case_when(
        MDS3 == 0 & MDS3NA == 1 ~ NA_real_,
        MDS3 == 0 & MDS3NA == 0 & is.na(DS3) ~ 0,
        TRUE ~ DS3
      ),
      
      # Handle MPT (pre-dorsal pterygiophores)
      MPT = case_when(
        MPT == 0 & (MDS1 == 1 | MDS2 == 1 | MDS3 == 1) ~ NA_real_,
        TRUE ~ MPT
      ),
      
      # Handle pelvic spine columns
      PSP.L = case_when(
        MPSP == 0 & MPSPNA == 1 ~ NA_real_,
        TRUE ~ PSP.L
      ),
      PSP.R = case_when(
        MPSP == 0 & MPSPNA == 1 ~ NA_real_,
        TRUE ~ PSP.R
      )
    )
  
  # When TPGNA column is available, apply similar logic to TPG
  if ("TPGNA" %in% names(cleaned)) {
    cleaned <- cleaned %>%
      mutate(
        TPG = case_when(
          TPGNA == 1 ~ NA_real_,
          TRUE ~ TPG
        )
      )
  }
  
  return(as.data.frame(cleaned))
}

```

## identify_overlaps
```{r}
identify_overlaps <- function(data, threshold = 0.05) {
  # Requires tidyr and dplyr
  
  # Define measurement columns
  measure_cols <- c("SL", "CAV", "DS1", "DS2", "DS3", "MDF", "MAF", "MCV", "MAV", 
                    "MPT", "LPT", "PSP.L", "PSP.R", "TPG", "ECT", "CLE", "PMX")
  
  # Step 1: Create separate dataframes for part and counterpart data
  part_data <- data %>% 
    filter(part_type == "P") %>%
    select(fish_id, part_type, row_id = n, Scale_10mm, all_of(measure_cols))
  
  cpart_data <- data %>% 
    filter(part_type == "C") %>%
    select(fish_id, part_type, row_id = n, Scale_10mm, all_of(measure_cols))
  
  # Step 2: Gather measurements into long format for easier comparison
  part_long <- part_data %>%
    pivot_longer(
      cols = all_of(measure_cols),
      names_to = "measure",
      values_to = "part_value"
    ) %>%
    filter(!is.na(part_value)) %>%
    select(fish_id, part_row_id = row_id, measure, part_value, part_scale = Scale_10mm)
  
  cpart_long <- cpart_data %>%
    pivot_longer(
      cols = all_of(measure_cols),
      names_to = "measure",
      values_to = "cpart_value"
    ) %>%
    filter(!is.na(cpart_value)) %>%
    select(fish_id, cpart_row_id = row_id, measure, cpart_value, cpart_scale = Scale_10mm)
  
  # Step 3: Join part and counterpart data to find overlaps
  overlaps <- part_long %>%
    inner_join(cpart_long, by = c("fish_id", "measure")) %>%
    mutate(
      scale = coalesce((part_scale + cpart_scale) / 2, part_scale, cpart_scale),
      absolute_diff = abs(part_value - cpart_value),
      relative_diff = absolute_diff / scale,
      exceeds_threshold = relative_diff > threshold
    )
  
  # Step 4: Get list of fish with overlaps
  fish_with_overlaps <- overlaps %>%
    select(fish_id) %>%
    distinct() %>%
    pull(fish_id)
  
  # Step 5: Separate fish with and without overlaps
  overlap_fish <- data %>%
    filter(fish_id %in% fish_with_overlaps)
  
  non_overlap_fish <- data %>%
    filter(!fish_id %in% fish_with_overlaps)
  
  # Convert results back to standard data.frames for consistency
  overlap_metrics <- as.data.frame(overlaps)
  overlap_fish <- as.data.frame(overlap_fish)
  non_overlap_fish <- as.data.frame(non_overlap_fish)
  
  return(list(
    overlap_fish = overlap_fish,
    non_overlap_fish = non_overlap_fish,
    overlap_metrics = overlap_metrics
  ))
}

```
## merge_non_overlap
```{r}
merge_non_overlap <- function(data) {
  # Load necessary packages
  if (!requireNamespace("dplyr", quietly = TRUE) ||
      !requireNamespace("tidyr", quietly = TRUE)) {
    install.packages(c("dplyr", "tidyr"))
  }
  library(dplyr)
  library(tidyr)
  
  # Get unique fish IDs
  fish_ids <- unique(data$fish_id)
  
  # Define measurement columns
  id_cols <- c("n", "ID", "fish_id", "part_type")
  measure_cols <- setdiff(names(data), id_cols)
  
  # Initialize empty dataframe for results
  result_list <- list()
  
  # Process each fish - some looping is still needed for the logical merging
  for (i in seq_along(fish_ids)) {
    id <- fish_ids[i]
    
    # Get all data for this fish
    fish_data <- data %>% 
      filter(fish_id == id)
    
    # If only one row, just use it directly
    if (nrow(fish_data) == 1) {
      result_list[[i]] <- fish_data
      next
    }
    
    # Step 1: Convert to long format (each measurement becomes a row)
    fish_long <- fish_data %>%
      pivot_longer(
        cols = all_of(measure_cols),
        names_to = "variable",
        values_to = "value"
      ) %>%
      filter(!is.na(value))  # Remove NA values
    
    # Step 2: Prioritize part rows (P) over counterpart rows (C)
    merged_values <- fish_long %>%
      group_by(variable) %>%
      arrange(variable, ifelse(part_type == "P", 1, 2)) %>%  # Sort P before C
      slice(1) %>%  # Take first row in each group (prioritizes P)
      ungroup()
    
    # Step 3: Convert back to wide format
    merged_row <- merged_values %>%
      select(variable, value) %>%
      pivot_wider(
        names_from = "variable",
        values_from = "value"
      ) 
    
    # Step 4: Add back fish_id and set part_type to "merged"
    merged_row <- merged_row %>%
      mutate(
        fish_id = id,
        part_type = "merged",
        merged = TRUE
      )
    
    # Add to result list
    result_list[[i]] <- merged_row
  }
  
  # Combine all results
  result <- bind_rows(result_list)
  
  return(as.data.frame(result))
}

```

## create_review_list
```{r}
create_review_list <- function(overlap_results, threshold = 0.05) {
  # Load necessary packages
  if (!requireNamespace("dplyr", quietly = TRUE)) {
    install.packages("dplyr")
  }
  library(dplyr)
  
  metrics <- overlap_results$overlap_metrics
  
  # Create summary by fish using dplyr grouping
  summary <- metrics %>%
    group_by(fish_id) %>%
    summarize(
      has_significant_diff = any(exceeds_threshold),
      num_overlapping_measures = n(),
      num_exceeding_threshold = sum(exceeds_threshold),
      max_relative_diff = max(relative_diff, na.rm = TRUE),
      .groups = "drop"
    ) %>%
    # Sort by number of concerning differences
    arrange(desc(num_exceeding_threshold), desc(max_relative_diff))
  
  # Create detailed list
  details <- metrics %>%
    arrange(fish_id, desc(relative_diff))
  
  return(list(
    summary = as.data.frame(summary),
    details = as.data.frame(details)
  ))
}

```

## export_review_list
```{r}
export_review_list <- function(review_results, file_prefix = "fish_review", output_dir = NULL) {
  # Create output directory if specified and it doesn't exist
  if (!is.null(output_dir)) {
    if (!dir.exists(output_dir)) {
      dir.create(output_dir, recursive = TRUE)
    }
    summary_path <- file.path(output_dir, paste0(file_prefix, "_summary.csv"))
    details_path <- file.path(output_dir, paste0(file_prefix, "_details.csv"))
  } else {
    summary_path <- paste0(file_prefix, "_summary.csv")
    details_path <- paste0(file_prefix, "_details.csv")
  }
  
  # Export files
  readr::write_csv(review_results$summary, summary_path)
  readr::write_csv(review_results$details, details_path)
  
  # Return file paths
  return(list(
    summary = summary_path,
    details = details_path
  ))
}

```

## clean_fish_data
```{r}
clean_fish_data <- function(data, threshold = 0.05) {
  # Load necessary packages
  if (!requireNamespace("dplyr", quietly = TRUE) ||
      !requireNamespace("tidyr", quietly = TRUE)) {
    install.packages(c("dplyr", "tidyr"))
  }
  library(dplyr)
  library(tidyr)
  
  # Step 1: Handle special cases for dorsal spines, etc.
  corrected_data <- handle_special_cases(data)
  
  # Step 2: Identify overlapping and non-overlapping fish
  overlap_results <- identify_overlaps_efficient(corrected_data, threshold)
  
  # Step 3: Merge the non-overlapping fish data
  merged_non_overlap <- merge_non_overlap_fish(overlap_results$non_overlap_fish)
  
  # Step 4: Add a validation step
  validation_results <- validate_data(
    original = data,
    corrected = corrected_data,
    merged = merged_non_overlap,
    overlaps = overlap_results$overlap_metrics
  )
  
  # Return results
  return(list(
    merged_data = merged_non_overlap,
    overlap_fish = overlap_results$overlap_fish,
    overlap_metrics = overlap_results$overlap_metrics,
    validation = validation_results,
    original_data = data
  ))
}

# Add a validation function to ensure data quality
validate_data <- function(original, corrected, merged, overlaps) {
  library(dplyr)
  
  # Initialize results
  validation <- list()
  
  # Check if any rows were lost
  total_specimens_original <- length(unique(original$fish_id))
  total_specimens_after <- length(unique(c(
    merged$fish_id, 
    unique(overlaps$fish_id)
  )))
  
  validation$all_specimens_accounted_for <- 
    total_specimens_original == total_specimens_after
  
  validation$specimen_counts <- tibble(
    stage = c("Original", "Merged", "Flagged for review", "Total after processing"),
    count = c(
      total_specimens_original,
      length(unique(merged$fish_id)),
      length(unique(overlaps$fish_id)),
      total_specimens_after
    )
  )
  
  # Check special case handling
  special_case_check <- corrected %>%
    filter(
      (MDS1 == 0 & MDS1NA == 1 & !is.na(DS1)) |
      (MDS2 == 0 & MDS2NA == 1 & !is.na(DS2)) |
      (MDS3 == 0 & MDS3NA == 1 & !is.na(DS3)) |
      (MPT == 0 & (MDS1 == 1 | MDS2 == 1 | MDS3 == 1)) |
      (MPSP == 0 & MPSPNA == 1 & (!is.na(PSP.L) | !is.na(PSP.R)))
    )
  
  validation$special_cases_properly_handled <- nrow(special_case_check) == 0
  validation$problematic_rows <- special_case_check
  
  return(validation)
}

```

```{r}


```

```{r}


```

```{r}


```

#==============================================================================#
# DATA IMPORT
```{r}
# Read in data and check initial structure
morph <- read.csv(paste0(p$`1.data/a.raw`, "241015_PitLMorph.csv"))
str(morph)
```

## ID Structure Analysis
```{r}
# Extract fish ID and part type
morph <- morph %>%
  mutate(
    fish_id = str_remove(ID, "_[PC]\\.jpg$"),
    part_type = str_extract(ID, "[PC](?=\\.jpg$)")
  )

# Count rows per fish and part type
fish_part_counts <- morph %>%
  group_by(fish_id, part_type) %>%
  summarise(row_count = n(), .groups = "drop") %>%
  pivot_wider(names_from = part_type, values_from = row_count, values_fill = 0)

# Check fish without both part types
missing_parts <- fish_part_counts %>%
  filter(P == 0 | C == 0)
sum(missing_parts$`NA`) # 14 fish without both "part" & "counter part"

# Fish with excessive rows
multi_row_fish <- fish_part_counts %>%
  filter(P > 1 | C > 1)
length(multi_row_fish$fish_id) # 361 fish with duplicate "parts" or "counter parts"

```

## Basic Quality Check
```{r}
# Check for implausible values in measurement columns
# Example for length measurements (adjust for your specific columns)
length_cols <- c("SL", "CAV", "DS1", "DS2", "DS3", "LPT", "PSP.L", "PSP.R", "TPG", "ECT", "CLE", "PMX")

# Check for negative values in length columns
negative_lengths <- morph %>%
  select(ID, all_of(length_cols)) %>%
  pivot_longer(cols = -ID, names_to = "measure", values_to = "value") %>%
  filter(value < 0)
length(negative_lengths$ID) # No negative measurements
```

#==============================================================================#
# SUMMARY STATS - PRE MERGE
## Measurement Availability
```{r}
# Calculate percentage of non-NA values by part type
measurement_availability <- morph %>%
  group_by(part_type) %>%
  summarise(across(-c(n, ID, fish_id), 
                   ~mean(!is.na(.x)) * 100,
                   .names = "pct_{.col}"))

```

## Overlap Assesment
```{r}
# For each fish, which measurements appear in both P and C?
# This will help understand potential duplication issues

# Convert data to long format
morph_long <- morph %>%
  pivot_longer(cols = -c(n, ID, fish_id, part_type), 
               names_to = "measure", 
               values_to = "value") %>%
  filter(!is.na(value))

# Find measurements that appear in both P and C for the same fish
duplicate_measures <- morph_long %>%
  group_by(fish_id, measure) %>%
  summarise(
    part_count = n_distinct(part_type),
    .groups = "drop"
  ) %>%
  filter(part_count > 1)

```
## Vizualization
```{r}
# Create a visualization of data completeness
ggplot(morph_long, aes(x = measure, fill = part_type)) +
  geom_bar(position = "dodge") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Measurement counts by part type",
       x = "Measurement",
       y = "Count")

```

#==============================================================================#
# DATA PREPROCESSING
## Handle Dorsal Spine and Pelvic Girdle Logic
```{r Spine and Girdle Logic}
# Apply logic for dorsal spines and pelvic girdle:
# - If *NA = 1, corresponding measurements should be NA (poor preservation)
# - If *NA = 0 and respective count = 0, length measurements should be 0 (biologically absent)

morph <- morph %>%
  mutate(
    # DS1 logic
    DS1 = case_when(
      MDS1NA == 1 ~ NA_real_,  # Poor preservation
      MDS1 == 0 & MDS1NA == 0 ~ 0, # Biologically absent
      TRUE ~ DS1  # Keep original value
    ),
    # DS2 logic
    DS2 = case_when(
      MDS2NA == 1 ~ NA_real_,  # Poor preservation
      MDS2 == 0 & MDS2NA == 0 ~ 0, # Biologically absent
      TRUE ~ DS2  # Keep original value
    ),
    # DS3 logic
    DS3 = case_when(
      MDS3NA == 1 ~ NA_real_,  # Poor preservation
      MDS3 == 0 & MDS3NA == 0 ~ 0, # Biologically absent
      TRUE ~ DS3  # Keep original value
    ),
    # Pelvic spine logic
    `PSP.L` = case_when(
      MPSPNA == 1 ~ NA_real_,  # Poor preservation
      MPSP == 0 & MPSPNA == 0 ~ 0, # Biologically absent
      TRUE ~ `PSP.L`  # Keep original value
    ),
    `PSP.R` = case_when(
      MPSPNA == 1 ~ NA_real_,  # Poor preservation
      MPSP == 0 & MPSPNA == 0 ~ 0, # Biologically absent
      TRUE ~ `PSP.R`  # Keep original value
    ),
    # Pelvic girdle length
    TPG = case_when(
      MPSPNA == 1 ~ NA_real_,  # Poor preservation if girdle uncertain
      TRUE ~ TPG  # Keep original value
      # Note: TPG can have a value even if MPSP=0, as fish can have a girdle without spines
    )
  )
```


#==============================================================================#
# DATA CLEANING
## Merge Redundant Part Types
```{r}
# Create lists of different column types
# Presence/absence columns - take maximum (if any row has 1, the feature is present)
presence_cols <- c("MDS1", "MDS2", "MDS3", "MPSP")

# Preservation uncertainty columns - take maximum (if any row has 1, preservation is uncertain)
preservation_cols <- c("MDS1NA", "MDS2NA", "MDS3NA", "MPSPNA")

# Count columns - take maximum value across rows (not sum, as these are counts per fish)
count_cols <- c("MDF", "MAF", "MCV", "MAV", "MPT")

# Measurement columns - take first non-NA value
measurement_cols <- c("SL", "CAV", "DS1", "DS2", "DS3", "LPT", "PSP.L", "PSP.R", 
                     "TPG", "ECT", "CLE", "PMX", "Scale_10mm")

# Create custom functions for each column type
max_function <- function(x) {
  if(all(is.na(x))) {
    return(NA)
  } else {
    return(max(x, na.rm = TRUE))
  }
}

first_non_na <- function(x) {
  if(all(is.na(x))) {
    return(NA)
  } else {
    return(x[min(which(!is.na(x)))])
  }
}

# Merge multiple rows for the same fish_id and part_type
merged_parts <- morph %>%
  group_by(fish_id, part_type) %>%
  summarise(
    # Take maximum for presence/absence columns
    across(all_of(presence_cols), max_function),
    # Take maximum for preservation uncertainty columns
    across(all_of(preservation_cols), max_function),
    # Take maximum for count columns (these are typically not distributed across rows)
    across(all_of(count_cols), max_function),
    # Take first non-NA for measurement columns
    across(all_of(measurement_cols), first_non_na),
    # Track how many rows were merged
    row_count = n(),
    .groups = "drop"
  )

# Check for implausible values in merged data
count_summary <- merged_parts %>%
  select(fish_id, part_type, all_of(count_cols)) %>%
  pivot_longer(cols = all_of(count_cols), 
               names_to = "measure", 
               values_to = "value") %>%
  group_by(measure) %>%
  summarise(
    min = min(value, na.rm = TRUE),
    max = max(value, na.rm = TRUE),
    mean = mean(value, na.rm = TRUE),
    median = median(value, na.rm = TRUE)
  )

print(count_summary)

# Check how many fish had multiple rows merged
merge_summary <- merged_parts %>%
  group_by(fish_id, part_type) %>%
  summarise(row_count = first(row_count), .groups = "drop") %>%
  filter(row_count > 1)

print(paste("Number of fish with multiple rows merged:", n_distinct(merge_summary$fish_id)))
```

## Flag Conflicting Measurements
```{r Flag Duplicates}
# List of actual measurement columns we want to check for conflicts
# These are columns with actual length measurements, not counts or presence indicators
measurement_cols_to_check <- c(
  "SL",    # Standard Length
  "CAV",   # Caudal Abdominal Vertebrae Length
  "DS1",   # Dorsal spine 1 length
  "DS2",   # Dorsal spine 2 length
  "DS3",   # Dorsal spine 3 length
  "LPT",   # Length of penultimate pre-dorsal pterygiophores
  "PSP.L", # Length of left pelvic spine
  "PSP.R", # Length of right pelvic spine
  "TPG",   # Pelvic girdle length
  "ECT",   # Ectocoracoid length
  "CLE",   # Cleithrum length
  "PMX"    # Premaxilla length
)

# Convert merged data to wide format with P and C columns
wide_merged <- merged_parts %>%
  pivot_wider(
    id_cols = fish_id,
    names_from = part_type,
    values_from = all_of(colnames(merged_parts)[!colnames(merged_parts) %in% c("fish_id", "part_type")]),
    names_glue = "{part_type}_{.value}"
  )

# Create a function to find duplicates (non-NA values in both P and C)
find_duplicates <- function(p_value, c_value) {
  if(!is.na(p_value) && !is.na(c_value)) {
    return(TRUE)
  } else {
    return(FALSE)
  }
}

# Create flags for duplicate measurements
flagged_data <- wide_merged

# Initialize empty list to store flags
flag_columns <- list()

# Check each measurement for duplicates
for(col in measurement_cols_to_check) {
  p_col <- paste0("P_", col)
  c_col <- paste0("C_", col)
  
  # Skip if columns don't exist (some might be missing from one part type)
  if(!(p_col %in% names(flagged_data) && c_col %in% names(flagged_data))) {
    next
  }
  
  # Create flag column
  flag_col <- paste0("flag_", col)
  flagged_data[[flag_col]] <- mapply(
    find_duplicates,
    flagged_data[[p_col]],
    flagged_data[[c_col]]
  )
  
  # Add to list of flag columns
  flag_columns <- c(flag_columns, flag_col)
}

# Count number of flags per fish
flagged_data <- flagged_data %>%
  mutate(total_flags = rowSums(across(all_of(unlist(flag_columns))), na.rm = TRUE))

# Create a column with all the flagged measurement names
flagged_data <- flagged_data %>%
  mutate(
    flagged_measurements = apply(
      flagged_data[, unlist(flag_columns), drop = FALSE], 
      1, 
      function(x) {
        paste(
          names(x)[x], 
          collapse = ", "
        ) %>% 
          str_remove_all("flag_")
      }
    )
  )

# Examine flags
flag_summary <- flagged_data %>%
  summarise(
    fish_with_flags = sum(total_flags > 0),
    total_flags = sum(total_flags),
    max_flags_per_fish = max(total_flags)
  )

print(flag_summary)

# Get counts by measurement type
flag_counts <- data.frame(
  measurement = unlist(flag_columns) %>% str_remove("flag_"),
  count = colSums(flagged_data[, unlist(flag_columns)], na.rm = TRUE)
)

print(flag_counts)

# Export for manual review
# Create a more manageable version with essential information
review_data <- flagged_data %>%
  select(
    fish_id, 
    total_flags, 
    flagged_measurements,
    matches("^[PC]_(SL|CAV|DS1|DS2|DS3|LPT|PSP\\.L|PSP\\.R|TPG|ECT|CLE|PMX)$")
  ) %>%
  filter(total_flags > 0) %>%
  arrange(desc(total_flags))

# Export the full dataset for complete context
write.csv(flagged_data, paste0(p$`1.data/c.flagged`, "all_flagged_measurements.csv"), row.names = FALSE)

# Export the more focused review dataset
write.csv(review_data, paste0(p$`1.data/c.flagged`, "review_flagged_measurements.csv"), row.names = FALSE)

```
## Visualize
```{r}
# Create a visualization of the flagged measurements
ggplot(flag_counts, aes(x = reorder(measurement, count), y = count)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Number of fish with duplicate measurements by type",
       x = "Measurement",
       y = "Count of fish with duplicates")

# Visualize distribution of flags per fish
ggplot(flagged_data %>% filter(total_flags > 0), 
       aes(x = total_flags)) +
  geom_histogram(binwidth = 1, fill = "coral") +
  theme_minimal() +
  labs(title = "Distribution of duplicate measurements per fish",
       x = "Number of duplicate measurements",
       y = "Count of fish")

```

