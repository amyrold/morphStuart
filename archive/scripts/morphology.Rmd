---
title: "morphStuart"
author: "Aaron Myrold"
date: "`r Sys.Date()`"
output: html_document
---

#==============================================================================#
# SETUP
```{r setup}
knitr::opts_knit$set(root.dir = dirname(getwd()))
```

```{r source}
# Source project setup and run config
source("src/project_setup.R")
setup_project('config.yaml')

```
#==============================================================================#
# DATA IMPORT
```{r}
# Source cleaning functions
source(paste0(p$src, "morph_cleaning.R"))
# Read in data and check initial structure
morph <- read.csv(paste0(p$data.raw, "020625_PitLMorph.csv"))
#str(morph)

# ADD LOGGING:
processing_log <- log_step(
  processing_log, 
  step_name = "Data Import",
  input_data = morph,
  notes = "Initial import of raw morphology data"
)

# ADD VALIDATION:
validate_step(
  morph, 
  step_name = "Data Import",
  required_columns = c("n", "ID", "SL", "Scale_10mm"),
  custom_checks = fish_data_checks[c("count_variable_logic")]  # This check now works without fish_id
)

```

## ID Structure Analysis
```{r}
# Extract fish ID and part type
# ID format: VXXXXXX_LXXXX(A)_1_P/C.jpg or VXXXXXX_LXXXX(A)_1_P2.jpg
# where VXXXXXX is the specimen ID, LXXXX(A) is the LSPEC/locality, and P/C indicates part/counterpart
morph_with_ids <- morph %>%
  mutate(
    fish_id = str_extract(ID, "^V\\d+"),                          # Extract VXXXXX part at beginning
    LSPEC_raw = str_extract(ID, "L\\d+[A-Za-z]?"),                  # Extract LXXXX with optional letter
    # Split LSPEC into letter prefix, number, and suffix
    LSPEC_letter = str_extract(LSPEC_raw, "^L"),
    LSPEC_number = str_extract(LSPEC_raw, "\\d+"),
    LSPEC_suffix = str_extract(LSPEC_raw, "[A-Za-z]$"),
    # Create standardized LSPEC with zero padding
    LSPEC = case_when(
      !is.na(LSPEC_suffix) ~ paste0(LSPEC_letter, str_pad(LSPEC_number, 4, pad = "0"), LSPEC_suffix),
      !is.na(LSPEC_number) ~ paste0(LSPEC_letter, str_pad(LSPEC_number, 4, pad = "0")),
      TRUE ~ NA_character_
    ),
    # Extract P or C (with optional numbers) before .jpg, then standardize
    part_type_raw = str_extract(ID, "[PC]\\d*(?=\\.jpg$)"),      # Extract P, P2, P3, etc. or C before .jpg
    part_type = case_when(
      str_starts(part_type_raw, "P") ~ "P",                      # Convert P, P2, P3, etc. to just "P"
      part_type_raw == "C" ~ "C",                                # Keep C as is
      TRUE ~ part_type_raw                                       # Preserve any unexpected values
    )
  ) %>%
  select(-LSPEC_raw, -LSPEC_letter, -LSPEC_number, -LSPEC_suffix, -part_type_raw)  # Remove intermediate columns


# ADD LOGGING:
processing_log <- log_step(
  processing_log,
  step_name = "ID Structure Analysis", 
  input_data = morph,
  output_data = morph_with_ids,
  notes = "Extracted fish_id and part_type from ID column"
)

# Continue with updated ids
morph <- morph_with_ids
```

## Basic Quality Check
```{r}
# Check for implausible values in measurement columns
length_cols <- c("SL", "CAV", "DS1", "DS2", "DS3", "LPT", "PSP.L", "PSP.R", "TPG", "ECT", "CLE", "PMX")

# Check for negative values in length columns
negative_lengths <- morph %>%
  select(ID, all_of(length_cols)) %>%
  pivot_longer(cols = -ID, names_to = "measure", values_to = "value") %>%
  filter(value < 0)
length(negative_lengths$ID) # No negative measurements

```

## Flag missing Scale_10mm
```{r}
# Check for missing scale information
scale_summary <- morph %>%
  group_by(fish_id) %>%
  summarize(
    has_part_scale = any(!is.na(Scale_10mm[part_type == "P"])),
    has_cpart_scale = any(!is.na(Scale_10mm[part_type == "C"])),
    has_any_scale = has_part_scale | has_cpart_scale,
    .groups = "drop"
  )

# Get list of fish IDs missing scales
fish_missing_scales <- scale_summary %>%
  filter(!has_any_scale) %>%
  pull(fish_id)

# Create report of fish missing scale information
missing_scales_detail <- morph %>%
  filter(fish_id %in% fish_missing_scales) %>%
  select(fish_id, ID, part_type, Scale_10mm) %>%
  arrange(fish_id, part_type)

# Write the detailed report
write.csv(missing_scales_detail, 
          file = paste0(p$data.flagged, "fish_missing_scales_detailed.csv"), 
          row.names = FALSE)

# Print summary of scale check
cat("Fish without any scale information:", 
    sum(!scale_summary$has_any_scale), 
    "out of", nrow(scale_summary), "\n")

# Split the dataset
morph_with_scales <- morph %>%
  filter(!fish_id %in% fish_missing_scales)

morph_without_scales <- morph %>%
  filter(fish_id %in% fish_missing_scales)

# ADD LOGGING:
processing_log <- log_step(
  processing_log,
  step_name = "Scale Filtering",
  input_data = morph,
  output_data = morph_with_scales,
  notes = paste("Removed", length(fish_missing_scales), "fish without scale measurements")
)

# Continue with the fish that have scale measurements
morph <- morph_with_scales

# Write the datasets to separate files for reference
write.csv(morph_with_scales, 
          file = paste0(p$data.raw, "fish_with_scales.csv"), 
          row.names = FALSE)

write.csv(morph_without_scales, 
          file = paste0(p$data.flagged, "fish_without_scales.csv"), 
          row.names = FALSE)
```

#==============================================================================#
# DATA PREPROCESSING
## Handle Special Cases
```{r Spine and Girdle Logic}

morph_corrected <- handle_special_cases(morph)

# ADD LOGGING:
processing_log <- log_step(
  processing_log,
  step_name = "Special Cases Handling",
  input_data = morph_with_scales,
  output_data = morph_corrected,
  notes = "Applied spine and girdle logic rules"
)

```

## Overlap Assesment
```{r}
overlap_results <- identify_overlaps(morph_corrected, threshold = 0.05)

# ADD LOGGING:
processing_log <- log_step(
  processing_log,
  step_name = "Overlap Assessment",
  input_data = morph_corrected,
  notes = paste("Identified", length(unique(overlap_results$overlap_fish$fish_id)), 
                "fish with conflicts")
)
# Summarize overlap findings
cat("Number of fish with overlapping measurements:", 
    length(unique(overlap_results$overlap_metrics$fish_id)), "\n")
cat("Number of fish without overlaps:", 
    length(unique(overlap_results$non_overlap_fish$fish_id)), "\n")

```

#==============================================================================#
# DATA CLEANING
## Merge Non-Overlapping Fish
```{r}
merged_non_overlap <- merge_non_overlap(overlap_results$non_overlap_fish)

# Write merged data for Non-Overlapping Fish
merged_file <- write.csv(merged_non_overlap, 
          file = paste0(p$data.intermediate, "merged_non_overlap.csv"))

# ADD LOGGING:
processing_log <- log_step(
  processing_log,
  step_name = "Merge Non-Overlapping Fish",
  input_data = overlap_results$non_overlap_fish,
  output_data = merged_non_overlap,
  files_created = merged_file,
  notes = "Merged part and counterpart data"
)

```

## Flag Conflicting Measurements
```{r Flag Duplicates}
# Create review list with threshold filtering applied (default)
review_results <- create_review_list(overlap_results, use_threshold = TRUE)

# Or to see all overlaps without threshold filtering:
# review_results_all <- create_review_list(overlap_results, use_threshold = FALSE)

export_review_list(review_results, file_prefix = "fish_fossil_review",
                   output_dir = p$data.flagged)

# ADD LOGGING:
processing_log <- log_step(
  processing_log,
  step_name = "Flag Conflicting Measurements",
  input_data = overlap_results$overlap_fish,
  notes = paste("Created review lists for", nrow(review_results$summary), "fish")
)

```

## Visualize Results
```{r}
# Get the filtered metrics that only include real overlaps
filtered_metrics <- review_results$filtered_metrics

# Create a suffix for titles based on whether threshold filtering was used
threshold_text <- if(review_results$use_threshold) " (Exceeding Threshold)" else " (All Overlaps)"

# Visualization 1: Distribution of relative differences
p1 <-ggplot(filtered_metrics, aes(x = relative_diff)) +
  geom_histogram(bins = 30, fill = "skyblue", color = "black") +
  geom_vline(xintercept = 0.05, color = "red", linetype = "dashed") +
  labs(title = paste0("Distribution of Relative Differences", threshold_text),
       x = "Relative Difference (proportion of scale)",
       y = "Count") +
  theme_minimal()
ggsave(paste0(p$results.figures.morphology, "overlap_relative_differences.svg"), p1, width = 10, height = 6)

# Visualization 2: Count of overlaps by measurement type
overlap_by_measure <- filtered_metrics %>%
  group_by(measure) %>%
  summarise(
    count = n(),
    avg_diff = mean(relative_diff, na.rm = TRUE),
    .groups = "drop"
  )

p2 <- ggplot(overlap_by_measure, aes(x = reorder(measure, count), y = count)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = paste0("Number of fish with duplicate measurements by type", threshold_text),
       x = "Measurement",
       y = "Count of fish with duplicates") 
ggsave(paste0(p$results.figures.morphology, "overlaps_by_measure.svg"), p2, width = 10, height = 6)

# Visualization 3: Distribution of flags per fish
p3 <- ggplot(review_results$summary, aes(x = total_diffs)) +
  geom_histogram(binwidth = 1, fill = "coral") +
  theme_minimal() +
  labs(title = paste0("Distribution of duplicate measurements per fish", threshold_text),
       x = "Number of duplicate measurements",
       y = "Count of fish")
ggsave(paste0(p$results.figures.morphology, "duplicates_per_fish.svg"), p3, width = 8, height = 6)

# Visualization 4: Distribution of differences by variable type
p4 <- ggplot(filtered_metrics, 
       aes(x = var_type, y = absolute_diff, fill = var_type)) +
  geom_boxplot() +
  scale_fill_brewer(palette = "Set2") +
  theme_minimal() +
  labs(title = paste0("Distribution of Differences by Variable Type", threshold_text),
       x = "Variable Type", 
       y = "Absolute Difference",
       fill = "Variable Type") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
ggsave(paste0(p$results.figures.morphology, "differences_by_variable_type.svg"), p4, width = 10, height = 6)
```
#==============================================================================#









